{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key=\"bad6b8a0ac53c6665bbf6201ac36a3ab180041b7\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:10:41.469581Z","iopub.execute_input":"2025-04-07T17:10:41.469854Z","iopub.status.idle":"2025-04-07T17:10:50.817751Z","shell.execute_reply.started":"2025-04-07T17:10:41.469822Z","shell.execute_reply":"2025-04-07T17:10:50.817099Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshravang\u001b[0m (\u001b[33mshravang-iiit-hyderabad\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom datasets import load_dataset, Dataset, load_from_disk\nfrom transformers import (\n    Trainer,\n    TrainingArguments,\n    TrainerCallback\n)\nfrom transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr, spearmanr\nfrom tqdm.auto import tqdm\n\n##############################################\n# Custom Epoch-Level Progress Callback       #\n##############################################\nclass SingleEpochProgressCallback(TrainerCallback):\n    def on_epoch_begin(self, args, state, control, **kwargs):\n        print(f\"\\nStarting epoch {state.epoch:.0f}/{args.num_train_epochs}\")\n        # Calculate steps per epoch if available.\n        if state.max_steps and args.num_train_epochs:\n            self.steps_per_epoch = int(state.max_steps / args.num_train_epochs)\n        else:\n            self.steps_per_epoch = 0\n        self.progress_bar = tqdm(total=self.steps_per_epoch, desc=f\"Epoch {state.epoch:.0f}\")\n    def on_step_end(self, args, state, control, **kwargs):\n        if hasattr(self, \"progress_bar\"):\n            self.progress_bar.update(1)\n    def on_epoch_end(self, args, state, control, **kwargs):\n        if hasattr(self, \"progress_bar\"):\n            self.progress_bar.close()\n\n##############################################\n# Device and Dataset Paths                   #\n##############################################\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\nlanguages = ['de','en','es','fr','it','nl','pl','pt','ru','zh']\ntrain_path = \"/kaggle/working/distilbert_combined_train\"\nval_path   = \"/kaggle/working/distilbert_combined_dev\"\n\n##############################################\n# Dataset Loading & Combining                #\n##############################################\ndef load_and_combine_split(split_name):\n    print(f\"Loading split '{split_name}' for all languages...\")\n    combined_examples = []\n    for lang in languages:\n        print(f\"Loading language: {lang}\")\n        ds = load_dataset(\"PhilipMay/stsb_multi_mt\", lang, split=split_name)\n        print(f\"Number of examples for {lang}: {len(ds)}\")\n        combined_examples.extend(ds)\n    print(\"Creating combined dataset...\")\n    return Dataset.from_dict({\n        \"sentence1\": [ex[\"sentence1\"] for ex in combined_examples],\n        \"sentence2\": [ex[\"sentence2\"] for ex in combined_examples],\n        \"similarity_score\": [ex[\"similarity_score\"] for ex in combined_examples],\n    })\n\nif os.path.exists(train_path):\n    train_dataset = load_from_disk(train_path)\n    print(\"Loaded combined train dataset from disk.\")\nelse:\n    print(\"Loading and combining training split...\")\n    train_dataset = load_and_combine_split(\"train\")\n    train_dataset.save_to_disk(train_path)\n    print(\"Saved combined train dataset to disk.\")\n\nif os.path.exists(val_path):\n    val_dataset = load_from_disk(val_path)\n    print(\"Loaded combined validation dataset from disk.\")\nelse:\n    print(\"Loading and combining validation split...\")\n    val_dataset = load_and_combine_split(\"dev\")\n    val_dataset.save_to_disk(val_path)\n    print(\"Saved combined validation dataset to disk.\")\n\n# Optionally set dataset format to torch.\ntrain_dataset.set_format(\"torch\")\nval_dataset.set_format(\"torch\")\nprint(\"Train dataset size:\", len(train_dataset))\nprint(\"Validation dataset size:\", len(val_dataset))\n\n##############################################\n# Model and Tokenizer                        #\n##############################################\n\nmodel_name = \"distilbert-base-multilingual-cased\"\ntokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n\ndef model_init():\n    model = DistilBertForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=1,                # For regression\n        problem_type=\"regression\"    # Ensure proper handling of regression tasks\n    )\n    model.config.use_cache = False\n    model.to(device)\n    return model\n\n##############################################\n# Preprocessing & Tokenization               #\n##############################################\ndef preprocess_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True, max_length=128)\n\nprint(\"Tokenizing train dataset...\")\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nprint(\"Tokenizing validation dataset...\")\nval_dataset = val_dataset.map(preprocess_function, batched=True)\n\ndef set_labels(example):\n    example[\"labels\"] = float(example[\"similarity_score\"])\n    return example\n\nprint(\"Setting labels for train dataset...\")\ntrain_dataset = train_dataset.map(set_labels)\nprint(\"Setting labels for validation dataset...\")\nval_dataset = val_dataset.map(set_labels)\n\n##############################################\n# Metrics Calculation                        #\n##############################################\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = predictions.flatten()\n    pearson_corr = pearsonr(predictions, labels)[0]\n    spearman_corr = spearmanr(predictions, labels)[0]\n    mse = mean_squared_error(labels, predictions)\n    pred_array = np.array(predictions)\n    label_array = np.array(labels)\n    dot = np.dot(pred_array, label_array)\n    norm_pred = np.linalg.norm(pred_array)\n    norm_label = np.linalg.norm(label_array)\n    cosine_sim = dot / (norm_pred * norm_label) if norm_pred and norm_label else 0.0\n    return {\n        \"pearson\": pearson_corr,\n        \"spearman\": spearman_corr,\n        \"mse\": mse,\n        \"cosine\": cosine_sim,\n        \"avg_corr\": (pearson_corr + spearman_corr) / 2\n    }\n\n##############################################\n# Training Arguments                         #\n##############################################\ntraining_args = TrainingArguments(\n    output_dir=\"./distilbert_sts_finetuned\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    fp16=True,\n    save_total_limit=2,\n    dataloader_num_workers=4\n)\n\nprint(\"Starting training for DistilBERT...\")\ntrainer = Trainer(\n    model_init=model_init,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    tokenizer=tokenizer,\n)\ntrainer.add_callback(SingleEpochProgressCallback())\n\ntrainer.train()\neval_results = trainer.evaluate()\nprint(\"DistilBERT Evaluation results:\", eval_results)\n\n# Save the final model after training.\nfinal_model = trainer.model\nfinal_model.save_pretrained(\"./distilbert_sts_finetuned\")\nprint(\"Final model saved at './distilbert_sts_finetuned'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:10:58.722125Z","iopub.execute_input":"2025-04-07T17:10:58.722510Z","iopub.status.idle":"2025-04-07T17:30:57.848747Z","shell.execute_reply.started":"2025-04-07T17:10:58.722479Z","shell.execute_reply":"2025-04-07T17:30:57.847705Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading and combining training split...\nLoading split 'train' for all languages...\nLoading language: de\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19da1eec7bae468da4dac8f0a00d32c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/537k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"451d1076535e416297f186fb82f4c7cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/123k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde616d7d9be4f50a8b7543bd2ff9944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/163k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d942551e3d15472c983ac3d296983895"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a245ba98449e41c4b655962a3400c279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17c5c558ec64f0682969c8717cd3fa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0605c803c44945369b53fd0595b97fdc"}},"metadata":{}},{"name":"stdout","text":"Number of examples for de: 5749\nLoading language: en\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/470k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ab335be0c24d8b8f2b08cab7618e3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/108k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88351e7ec5d54b7cac2ad2397cde7d64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/142k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803138fb5cf641b38a02eb540c2605df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d27e309fb6f449e89b5cf7c268e5994"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21cac90d2a7242959d4f57e989a71c24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1516f731c2141ea8c2b1dce7914db73"}},"metadata":{}},{"name":"stdout","text":"Number of examples for en: 5749\nLoading language: es\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/528k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1aa416224584ae08dc28c9a932f9ef8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/119k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68084d489c4740c190280604b207130d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/157k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a749953ae19c412ebac51d345182766f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d4ab0019e72406b89edd62ee773b19d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599c385d6fcd435d913c1f47ec2d89e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c3107cf29b24efc864849a40faae22d"}},"metadata":{}},{"name":"stdout","text":"Number of examples for es: 5749\nLoading language: fr\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/542k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a6145bc36244c6f83a91b4c3de6071f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/123k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcbcb812f2204d5087eac5c5acb746af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/163k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4628774cbc4a4e90d5e72d0506806c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2edc095d9a4d4a9c7dcdb01a7f8e9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a3b48c6cff47a18e9f6f12f4973998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c10c791e9d347dabf99c07cf883dd9e"}},"metadata":{}},{"name":"stdout","text":"Number of examples for fr: 5749\nLoading language: it\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/532k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42fb37f7eba0411caa524141994acbd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/122k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4f840b9892497b8228a0a00815d9d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/159k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30a7ff55a1004789928d8ba785b51d39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b09f32ea2a40b88eac384e432dce3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d42a830871c4b4b95833a22ccd9b79b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60571e1ac2734426a12c2461db20bdfa"}},"metadata":{}},{"name":"stdout","text":"Number of examples for it: 5749\nLoading language: nl\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/517k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfb2d62d6c540459934a702422ebce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708fc593142a42a9a20c90aa4546f6e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/153k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2fb3ab47df74fb69d519a573ff945e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfbd632877445f3a75dfe6679bc9fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3196ca24930e4b21941f7116cd30b6a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56981961aa324519b4658e2ec3cb13a0"}},"metadata":{}},{"name":"stdout","text":"Number of examples for nl: 5749\nLoading language: pl\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/546k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4228c3863e70495bb1fad752a7640217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/123k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94773e5aef54115bba960a0fdc492f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/164k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"103eb624f471427e8c02a80120ec6830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a5677c50acd41cdbf8cd0ae37e12da8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c184a1e71b844e994324c1486631c32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d815f5d34de14054ac55d0bb70720d54"}},"metadata":{}},{"name":"stdout","text":"Number of examples for pl: 5749\nLoading language: pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/523k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8560d950d04bacb7a86dcda906d8dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/119k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee3c86caea248cd96e594d86cf39323"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/158k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75ee3bf36f63491396308ca44f051739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7011103b57094788a180c1330ac1b57f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724a0abb6f2f4df8a21231cbb113ec9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94c2e8dd13cd415e9e6bf9c7d51d02c9"}},"metadata":{}},{"name":"stdout","text":"Number of examples for pt: 5749\nLoading language: ru\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/721k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe6f478bb3c4c80b16a59ba3c2583e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/158k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d6493e2de746869ddbed0195c808da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/209k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91698ba8dc32427792f3df079fd94ecd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329c5ca553e747e788bf7df61ca950c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fe745bcbdb745d0a421ccca2915494c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6229a5330f8d4a3994b2e4b7bbbd3432"}},"metadata":{}},{"name":"stdout","text":"Number of examples for ru: 5749\nLoading language: zh\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/468k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9926012224a45b1aef9b8e19eaf6a25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/107k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c07f9bc44be54ba28bb7d88d77a7736e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/140k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5780a57f46945b0baa044fc17957b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75f1b4abc7d440af835a95fef207d2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f26d50ef5a4de4aa3ccec125665d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6700173f1cd46f6b9de3268907b3e3f"}},"metadata":{}},{"name":"stdout","text":"Number of examples for zh: 5749\nCreating combined dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/57490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9d170d937a4fa080d9c684ed33b313"}},"metadata":{}},{"name":"stdout","text":"Saved combined train dataset to disk.\nLoading and combining validation split...\nLoading split 'dev' for all languages...\nLoading language: de\nNumber of examples for de: 1500\nLoading language: en\nNumber of examples for en: 1500\nLoading language: es\nNumber of examples for es: 1500\nLoading language: fr\nNumber of examples for fr: 1500\nLoading language: it\nNumber of examples for it: 1500\nLoading language: nl\nNumber of examples for nl: 1500\nLoading language: pl\nNumber of examples for pl: 1500\nLoading language: pt\nNumber of examples for pt: 1500\nLoading language: ru\nNumber of examples for ru: 1500\nLoading language: zh\nNumber of examples for zh: 1500\nCreating combined dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"355766713add4bf49fc858402f8ff769"}},"metadata":{}},{"name":"stdout","text":"Saved combined validation dataset to disk.\nTrain dataset size: 57490\nValidation dataset size: 15000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556cae99317e473ea2f85c8864730745"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd02e84b0904bb7bca847d7d15969b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ae5b3a82ce46ce9eb3529f719bbe28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0396c32e3c1e438c80130b29bc66cfc4"}},"metadata":{}},{"name":"stdout","text":"Tokenizing train dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/57490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d744143f7944cc380c866f4ad730f6e"}},"metadata":{}},{"name":"stdout","text":"Tokenizing validation dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a223ac64e374aa7a91b138d353cfaf5"}},"metadata":{}},{"name":"stdout","text":"Setting labels for train dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/57490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f99a4ad22054e97a47df4b599d1d32b"}},"metadata":{}},{"name":"stdout","text":"Setting labels for validation dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1acf813658ee47a7af34f606e4aecfab"}},"metadata":{}},{"name":"stdout","text":"Starting training for DistilBERT...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-2-f5bc3430c1bf>:164: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028fdd97c59843a7801ab9f2d567b8d3"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250407_171254-crlusy7f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shravang-iiit-hyderabad/huggingface/runs/crlusy7f' target=\"_blank\">./distilbert_sts_finetuned</a></strong> to <a href='https://wandb.ai/shravang-iiit-hyderabad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shravang-iiit-hyderabad/huggingface' target=\"_blank\">https://wandb.ai/shravang-iiit-hyderabad/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shravang-iiit-hyderabad/huggingface/runs/crlusy7f' target=\"_blank\">https://wandb.ai/shravang-iiit-hyderabad/huggingface/runs/crlusy7f</a>"},"metadata":{}},{"name":"stdout","text":"\nStarting epoch 0/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 0:   0%|          | 0/3594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802ddb039d34432ba1d1a90eaef98f8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10782' max='10782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10782/10782 17:37, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n      <th>Spearman</th>\n      <th>Mse</th>\n      <th>Cosine</th>\n      <th>Avg Corr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.795800</td>\n      <td>0.764680</td>\n      <td>0.818078</td>\n      <td>0.818142</td>\n      <td>0.764680</td>\n      <td>0.950611</td>\n      <td>0.818110</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.365800</td>\n      <td>0.754525</td>\n      <td>0.816555</td>\n      <td>0.814199</td>\n      <td>0.754525</td>\n      <td>0.950853</td>\n      <td>0.815377</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222500</td>\n      <td>0.791248</td>\n      <td>0.809870</td>\n      <td>0.807430</td>\n      <td>0.791248</td>\n      <td>0.949145</td>\n      <td>0.808650</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nStarting epoch 1/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/3594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b781a521488642d5867583e6ad638de7"}},"metadata":{}},{"name":"stdout","text":"\nStarting epoch 2/3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/3594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6331f0dbe9840deb6ddad0e1b501182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [938/938 00:16]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"DistilBERT Evaluation results: {'eval_loss': 0.7912477254867554, 'eval_pearson': 0.8098701242675328, 'eval_spearman': 0.8074295370780157, 'eval_mse': 0.7912477254867554, 'eval_cosine': 0.9491446614265442, 'eval_avg_corr': 0.8086498306727743, 'eval_runtime': 16.5014, 'eval_samples_per_second': 909.013, 'eval_steps_per_second': 56.844, 'epoch': 3.0}\nFinal model saved at './distilbert_sts_finetuned'.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport pandas as pd\nfrom datasets import load_from_disk, load_dataset, concatenate_datasets, Dataset\nfrom transformers import (\n    DistilBertForSequenceClassification,\n    DistilBertTokenizerFast,\n    Trainer,\n    TrainingArguments,\n    DistilBertConfig\n)\nfrom scipy.stats import pearsonr, spearmanr\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.auto import tqdm\nimport logging\n\n# Suppress transformer warnings.\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n##############################################\n# Define Languages and Concatenation Function#\n##############################################\nlanguages = ['de','en','es','fr','it','nl','pl','pt','ru','zh']\n\ndef load_and_concatenate_split(split_name):\n    print(f\"Loading split '{split_name}' for all languages...\")\n    datasets_list = []\n    for lang in languages:\n        print(f\"Loading language {lang}...\")\n        ds = load_dataset(\"PhilipMay/stsb_multi_mt\", lang, split=split_name)\n        datasets_list.append(ds)\n    print(\"Concatenating datasets from all languages...\")\n    combined_dataset = concatenate_datasets(datasets_list)\n    return combined_dataset\n\n##############################################\n# Matching Configuration                     #\n##############################################\nconfig = DistilBertConfig.from_pretrained(\"distilbert-base-multilingual-cased\")\nconfig.num_labels = 1\nconfig.problem_type = \"regression\"\nconfig.use_cache = False\n\n##############################################\n# Load the Fine-Tuned Model (Non-Quantized)    #\n##############################################\nmodel_path = \"/kaggle/working/distilbert_sts_finetuned\"  # Use your non-quantized DistilBERT checkpoint.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = DistilBertForSequenceClassification.from_pretrained(model_path, config=config)\nmodel.to(device)\nmodel.eval()\n\n##############################################\n# Load the Tokenizer                         #\n##############################################\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-multilingual-cased\")\n\n##############################################\n# Load and Prepare the Test Dataset          #\n##############################################\ntest_path = \"/kaggle/working/combined_test\"\nif os.path.exists(test_path):\n    test_dataset = load_from_disk(test_path)\n    print(\"Loaded combined test dataset from disk.\")\nelse:\n    print(\"Combined test dataset not found on disk; generating concatenated test dataset on the fly...\")\n    test_dataset = load_and_concatenate_split(\"test\")\n    test_dataset.save_to_disk(test_path)\n\n# Tokenize test data if needed.\nif \"input_ids\" not in test_dataset.column_names:\n    def preprocess_function(example):\n        return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True, max_length=128)\n    test_dataset = test_dataset.map(preprocess_function, batched=True, desc=\"Tokenizing\")\n\n# Ensure the labels are correctly set.\nif \"labels\" not in test_dataset.column_names:\n    def set_labels(example):\n        example[\"labels\"] = float(example[\"similarity_score\"])\n        return example\n    test_dataset = test_dataset.map(set_labels, desc=\"Setting labels\")\n\ntest_dataset.set_format(\"torch\")\n\n##############################################\n# Setup Trainer (Using GPU)                  #\n##############################################\ntraining_args = TrainingArguments(\n    output_dir=\"./eval_results\",\n    per_device_eval_batch_size=16,\n    logging_strategy=\"no\",\n    report_to=None\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer\n)\n\n##############################################\n# Manual Evaluation Loop with Progress Bar   #\n##############################################\neval_dataloader = trainer.get_eval_dataloader()\nall_preds = []\n\nfor batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n    # Move batch to GPU.\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n    all_preds.append(outputs.logits.cpu().numpy())\n\npreds = np.concatenate(all_preds).flatten()\n\n# Also get gold scores and original sentences.\ngold_scores = np.array(test_dataset[\"similarity_score\"])\nsentences1 = test_dataset[\"sentence1\"]\nsentences2 = test_dataset[\"sentence2\"]\n\n##############################################\n# Generate CSV with Predictions              #\n##############################################\ndf = pd.DataFrame({\n    \"sentence1\": sentences1,\n    \"sentence2\": sentences2,\n    \"gold_similarity_score\": gold_scores,\n    \"predicted_similarity_score\": preds\n})\n\noutput_csv_path = \"./evaluation_results.csv\"\ndf.to_csv(output_csv_path, index=False)\nprint(f\"CSV file with evaluation results saved at: {output_csv_path}\")\n\n##############################################\n# Compute Metrics (Optional)                 #\n##############################################\ndef compute_metrics_from_preds(preds, gold):\n    pearson_corr = pearsonr(preds, gold)[0]\n    spearman_corr = spearmanr(preds, gold)[0]\n    mse = mean_squared_error(gold, preds)\n    dot = np.dot(preds, gold)\n    norm_pred = np.linalg.norm(preds)\n    norm_gold = np.linalg.norm(gold)\n    cosine_sim = dot / (norm_pred * norm_gold) if norm_pred and norm_gold else 0.0\n    avg_corr = (pearson_corr + spearman_corr) / 2.0\n    return {\n        \"pearson\": pearson_corr,\n        \"spearman\": spearman_corr,\n        \"mse\": mse,\n        \"cosine\": cosine_sim,\n        \"avg_corr\": avg_corr\n    }\n\nmetrics = compute_metrics_from_preds(preds, gold_scores)\nprint(\"Evaluation Metrics:\")\nprint(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:18:13.519912Z","iopub.execute_input":"2025-04-07T18:18:13.520250Z","iopub.status.idle":"2025-04-07T18:18:48.989998Z","shell.execute_reply.started":"2025-04-07T18:18:13.520228Z","shell.execute_reply":"2025-04-07T18:18:48.989102Z"}},"outputs":[{"name":"stdout","text":"Combined test dataset not found on disk; generating concatenated test dataset on the fly...\nLoading split 'test' for all languages...\nLoading language de...\nLoading language en...\nLoading language es...\nLoading language fr...\nLoading language it...\nLoading language nl...\nLoading language pl...\nLoading language pt...\nLoading language ru...\nLoading language zh...\nConcatenating datasets from all languages...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/13790 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82116023242347d9aec8eec5977d17ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/13790 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99561b83f56643cc800b3f93a2c6a0e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Setting labels:   0%|          | 0/13790 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88eae95079e9433091b866480d7171a8"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-8-a2251a9aa48d>:96: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/862 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d726efb3e94226b9b728206247bf13"}},"metadata":{}},{"name":"stdout","text":"CSV file with evaluation results saved at: ./evaluation_results.csv\nEvaluation Metrics:\n{'pearson': 0.77267361810789, 'spearman': 0.7631519898382821, 'mse': 0.94900113, 'cosine': 0.9467342, 'avg_corr': 0.767912803973086}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!zip -r full_model.zip /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:31:30.131634Z","iopub.execute_input":"2025-04-07T17:31:30.132048Z","iopub.status.idle":"2025-04-07T17:33:59.046843Z","shell.execute_reply.started":"2025-04-07T17:31:30.132017Z","shell.execute_reply":"2025-04-07T17:33:59.045830Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/wandb/ (stored 0%)\n  adding: kaggle/working/wandb/debug.log (deflated 67%)\n  adding: kaggle/working/wandb/debug-internal.log (deflated 68%)\n  adding: kaggle/working/wandb/latest-run/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/wandb-metadata.json (deflated 47%)\n  adding: kaggle/working/wandb/latest-run/files/output.log (deflated 43%)\n  adding: kaggle/working/wandb/latest-run/files/requirements.txt (deflated 56%)\n  adding: kaggle/working/wandb/latest-run/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/logs/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/logs/debug.log (deflated 67%)\n  adding: kaggle/working/wandb/latest-run/logs/debug-internal.log (deflated 68%)\n  adding: kaggle/working/wandb/latest-run/logs/debug-core.log (deflated 58%)\n  adding: kaggle/working/wandb/latest-run/run-crlusy7f.wandb (deflated 77%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/ (stored 0%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/files/ (stored 0%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/files/wandb-metadata.json (deflated 47%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/files/output.log (deflated 43%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/files/requirements.txt (deflated 56%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/logs/ (stored 0%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/logs/debug.log (deflated 67%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/logs/debug-internal.log (deflated 68%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/logs/debug-core.log (deflated 58%)\n  adding: kaggle/working/wandb/run-20250407_171254-crlusy7f/run-crlusy7f.wandb (deflated 77%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/distilbert_combined_dev/ (stored 0%)\n  adding: kaggle/working/distilbert_combined_dev/dataset_info.json (deflated 58%)\n  adding: kaggle/working/distilbert_combined_dev/data-00000-of-00001.arrow (deflated 60%)\n  adding: kaggle/working/distilbert_combined_dev/state.json (deflated 39%)\n  adding: kaggle/working/distilbert_combined_train/ (stored 0%)\n  adding: kaggle/working/distilbert_combined_train/dataset_info.json (deflated 58%)\n  adding: kaggle/working/distilbert_combined_train/data-00000-of-00001.arrow (deflated 63%)\n  adding: kaggle/working/distilbert_combined_train/state.json (deflated 38%)\n  adding: kaggle/working/distilbert_sts_finetuned/ (stored 0%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/ (stored 0%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/training_args.bin (deflated 51%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/tokenizer.json (deflated 67%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/tokenizer_config.json (deflated 75%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/trainer_state.json (deflated 67%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/vocab.txt (deflated 45%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/optimizer.pt (deflated 50%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/rng_state.pth (deflated 25%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/config.json (deflated 46%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/scheduler.pt (deflated 55%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-10782/model.safetensors (deflated 7%)\n  adding: kaggle/working/distilbert_sts_finetuned/config.json (deflated 46%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/ (stored 0%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/training_args.bin (deflated 51%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/tokenizer.json (deflated 67%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/tokenizer_config.json (deflated 75%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/trainer_state.json (deflated 63%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/vocab.txt (deflated 45%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/optimizer.pt (deflated 50%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/rng_state.pth (deflated 25%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/config.json (deflated 46%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/scheduler.pt (deflated 55%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/distilbert_sts_finetuned/checkpoint-7188/model.safetensors (deflated 7%)\n  adding: kaggle/working/distilbert_sts_finetuned/runs/ (stored 0%)\n  adding: kaggle/working/distilbert_sts_finetuned/runs/Apr07_17-12-51_0a9273745299/ (stored 0%)\n  adding: kaggle/working/distilbert_sts_finetuned/runs/Apr07_17-12-51_0a9273745299/events.out.tfevents.1744047056.0a9273745299.31.1 (deflated 34%)\n  adding: kaggle/working/distilbert_sts_finetuned/runs/Apr07_17-12-51_0a9273745299/events.out.tfevents.1744045974.0a9273745299.31.0 (deflated 60%)\n  adding: kaggle/working/distilbert_sts_finetuned/model.safetensors (deflated 7%)\n","output_type":"stream"}],"execution_count":3}]}